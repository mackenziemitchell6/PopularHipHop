{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro='Yo Pierre, you wanna come out here? Yeah, huh, life is like a motherfuckin dream (Like a dream). Fill my doubleâ€…cup up with some lean (With some lean). Yeah, put my dick in your bitch spleen (Bitch spleen). Yeah, racks comin in evergreen (Evergreen).'\n",
    "chorus='Yeah, hold up, let me pop my shit. Pussy nigga talkin, we gon leave him in a ditch. Ill kill my brother, pussy nigga, if he snitch. I was outside being bad with The Grinch Nigga, bad with The Grinch.'\n",
    "\n",
    "verse='Yeah, yeah, trapping out the motherfuckin Ritz. Yeah, moving bales, nigga, yeah, moving bricks. Fucking on his thot and that bitch a redbone (Redbone). Yeah, yeah, put the bitch on (On), I put niggas on like some motherfuckin cologne. Fuck nigga, yeah, I aint singing, Post Malone, uh With the gang, we keep a fifty-seven (Buh-buh). And you know we keep some MAC-11s. I just love me some lethal weapons Child of God, Ill send your ass to heaven.'\n",
    "pre='Yeah, huh, life is like a motherfuckin dream (Like a dream). Fill my double cup up with some lean (With some lean). Yeah, put my dick in your bitch spleen (Bitch spleen). Yeah, racks comin in evergreen (Evergreen).'\n",
    "grinch=intro+' '+chorus+' '+verse+' '+pre+' '+chorus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yb=\"Ridin with that 40, ridin with that 40 with a beam, huh, yeah Dollar signs all I see. If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money, huh. ayy Ridin' with that 40, ridin' with that 40 with a beam, huh. yeah Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money. Hmm, I'm on the beach with my feet up, ayy. Everybody say I'm switchin', I don't speak up, no, hmm, ayy I just turn my speakers up, hmm, ayy I just turn my speakers up. huh I'm movin' on just like my lease was up. ayy And I'm still poppin' these Percs, lil' bitch, I'm geekin' up. huh I might fuck that lil' hoe if she freakin' though, ayy Then I have a new bitch 'fore the week was up. ayy Ridin' with that 40, ridin' with that 40 with a beam. huh, yeah Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money, huh. ayy Ridin' with that 40, ridin' with that 40 with a beam, huh, yeah. Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money (yeah, ayy, ayy). Now I come for that money, I got that green, yeah. I'm gunning for that cheese, yeah, that cheese, yeah. I run out with ya honey, she out of me, yeah. She wanna stay the week, I make her leave now, ayy. Get high, yeah, on the west side, yeah. On my life, yeah, think that I'ma die here. I put some money off to the side, yeah Take a ride with me, yeah. Ridin' with that 40, ridin' with that 40 with a beam, huh, yeah. Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money, huh, ayy. Ridin' with that 40, ridin' with that 40 with a beam, huh, yeah. Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah (ayy) If it ain't 'bout the money (ayy, gang). One day they caught me loafin' After droppin' off my bitch (droppin' off my bitch). They sent a couple shots But I'm just glad that nigga missed (on the gang, nigga). Ducked down and started clapping Tried to flip that hoe, whip (grra, pow, pow, pow) But I would rather take a life Before my my mama see me stiff (ayy, that's on my mama). So I'm clutchin' on that 44 when I'm trippin' (ayy, grra, pow, pow, pow) Trey paralyzed but I'm just glad that nigga livin' (Ayy, I'm just glad that nigga livin'). Please don't come to me when that nigga granny end up missin' (When that nigga end up missin') I was coolin' out in Cali, workin', bitch, I was gettin' it (Workin', bitch, I was gettin' it, huh). Ridin' with that 40, ridin' with that 40 with a beam, huh, yeah. Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money, huh, ayy. Ridin' with that 40, ridin' with that 40 with a beam, huh, yeah. Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money.\n",
      "Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money (yeah, ayy, ayy).\n",
      "Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah (ayy) If it ain't 'bout the money (ayy, gang).\n",
      "Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money, huh, ayy.\n",
      "Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money, huh, ayy.\n",
      "Dollar signs all I see If it ain't 'bout the money, I ain't worried 'bout it, yeah If it ain't 'bout the money.\n"
     ]
    }
   ],
   "source": [
    "print(summarize(yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install glove_python\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english')) \n",
    "doc=''\n",
    "for g in grinch.split(' '):\n",
    "    if g not in stop_words:\n",
    "        doc+=g+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yo Pierre, wanna come here? Yeah, huh, life like motherfuckin dream (Like dream). Fill double\\u2005cup lean (With lean). Yeah, put dick bitch spleen (Bitch spleen). Yeah, racks comin evergreen (Evergreen). Yeah, hold up, let pop shit. Pussy nigga talkin, gon leave ditch. Ill kill brother, pussy nigga, snitch. I outside bad The Grinch Nigga, bad The Grinch. Yeah, yeah, trapping motherfuckin Ritz. Yeah, moving bales, nigga, yeah, moving bricks. Fucking thot bitch redbone (Redbone). Yeah, yeah, put bitch (On), I put niggas like motherfuckin cologne. Fuck nigga, yeah, I aint singing, Post Malone, uh With gang, keep fifty-seven (Buh-buh). And know keep MAC-11s. I love lethal weapons Child God, Ill send ass heaven. Yeah, huh, life like motherfuckin dream (Like dream). Fill double cup lean (With lean). Yeah, put dick bitch spleen (Bitch spleen). Yeah, racks comin evergreen (Evergreen). Yeah, hold up, let pop shit. Pussy nigga talkin, gon leave ditch. Ill kill brother, pussy nigga, snitch. I outside bad The Grinch Nigga, bad The Grinch. '"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=doc.split('. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer as tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'very_large_data_dir_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-fc9c90f59004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membeddings_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvery_large_data_dir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'glove.6B.{}d.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'very_large_data_dir_path' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(very_large_data_dir_path, 'glove.6B.{}d.txt'.format(EMBEDDING_DIM)))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Tokenizer' has no attribute 'word_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-4f3e22fe02df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Words not found in glove will be zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Tokenizer' has no attribute 'word_index'"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(tokenizer.word_index)+1, EMBEDDING_DIM),dtype='float32')\n",
    "for word,i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "    # Words not found in glove will be zeros\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-43ec87845d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m embedding_layer = Embedding(len(tokenizer.word_index) + 1,    EMBEDDING_DIM, weights=[embedding_matrix],\n\u001b[0m\u001b[1;32m      2\u001b[0m input_length=MAX_INPUT_LENGTH, trainable=False,  name='embedding_layer')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Embedding' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(tokenizer.word_index) + 1,    EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "input_length=MAX_INPUT_LENGTH, trainable=False,  name='embedding_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeah, yeah, put bitch (On), I put niggas like motherfuckin cologne.\n",
      "Yeah, huh, life like motherfuckin dream (Like dream).\n",
      "Ill kill brother, pussy nigga, snitch.\n",
      "Ill kill brother, pussy nigga, snitch.\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "print(summarize(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_dictionary, common_corpus\n",
    "from gensim.models import LsiModel\n",
    "model = LsiModel(common_corpus, id2word=common_dictionary)\n",
    "vectorized_corpus = model[common_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-e2e51833409b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtextteaser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextTeaser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextTeaser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/textteaser/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtextteaser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextTeaser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_version'"
     ]
    }
   ],
   "source": [
    "from textteaser import TextTeaser\n",
    "tt = TextTeaser()\n",
    "tt.summarize(title, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textteaser in /Users/mackenziemitchell/anaconda3/lib/python3.7/site-packages (0.3)\n",
      "Requirement already satisfied: requests==1.2.3 in /Users/mackenziemitchell/anaconda3/lib/python3.7/site-packages (from textteaser) (1.2.3)\n",
      "\u001b[31mInvalid requirement: '_version'\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install textteaser\n",
    "!pip install _version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
